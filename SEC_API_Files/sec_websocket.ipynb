{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventtrader.keys import SEC_API_KEY  # Import directly from the package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "SERVER_URL = \"wss://stream.sec-api.io\"\n",
    "WS_ENDPOINT = SERVER_URL + \"?apiKey=\" + SEC_API_KEY\n",
    "async def websocket_client():\n",
    "    try:\n",
    "        async with websockets.connect(WS_ENDPOINT) as websocket:\n",
    "            print(\"✅ Connected to:\", SERVER_URL)\n",
    "            while True:\n",
    "                message = await websocket.recv()\n",
    "                filings = json.loads(message)\n",
    "                for f in filings:\n",
    "                    print(f\"Full filing info: {f}\")\n",
    "                    # print(f[\"accessionNo\"], f[\"formType\"], f[\"filedAt\"], f[\"cik\"])\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "# asyncio.run(websocket_client())\n",
    "await websocket_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original filing format: {'id': '2d18c83f53d9561f521252206a523cdb', 'accessionNo': '0001949846-25-000046', 'cik': '1773383', 'ticker': 'DT', 'companyName': 'Dynatrace, Inc.', 'companyNameLong': 'Dynatrace, Inc. (Subject)', 'formType': '144', 'description': 'Form 144 - Report of proposed sale of securities', 'filedAt': '2025-02-14T10:25:23-05:00', 'linkToTxt': 'https://www.sec.gov/Archives/edgar/data/1773383/000194984625000046/0001949846-25-000046.txt', 'linkToHtml': 'https://www.sec.gov/Archives/edgar/data/1773383/000194984625000046/0001949846-25-000046-index.htm', 'linkToXbrl': '', 'linkToFilingDetails': 'https://www.sec.gov/Archives/edgar/data/1773383/000194984625000046/xsl144X01/primary_doc.xml', 'entities': [{'companyName': 'Dynatrace, Inc. (Subject)', 'cik': '1773383', 'irsNo': '000000000', 'fiscalYearEnd': '0331', 'sic': '7372 Services-Prepackaged Software', 'undefined': '06 Technology)'}], 'documentFormatFiles': [{'sequence': '1', 'documentUrl': 'https://www.sec.gov/Archives/edgar/data/1773383/000194984625000046/xsl144X01/primary_doc.xml', 'type': '144', 'size': '\\xa0'}, {'sequence': '1', 'documentUrl': 'https://www.sec.gov/Archives/edgar/data/1773383/000194984625000046/primary_doc.xml', 'type': '144', 'size': '2966'}, {'sequence': '\\xa0', 'description': 'Complete submission text file', 'documentUrl': 'https://www.sec.gov/Archives/edgar/data/1773383/000194984625000046/0001949846-25-000046.txt', 'type': '\\xa0', 'size': '4442'}], 'dataFiles': [], 'seriesAndClassesContractsInformation': []}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Filter filings based on the \"formType\":\n",
    "\n",
    "- Keep filings where \"formType\" is one of ['8-K', '10-K', '10-Q', '8-K/A', '10-K/A', '10-Q/A']\n",
    "- Discard any filing where \"formType\" does not match the above list\n",
    "\n",
    "\n",
    "2. For each filing, process the data based on the \"formType\":\n",
    "a. If \"formType\" is one of ['10-K', '10-Q', '10-K/A', '10-Q/A']:\n",
    "\n",
    "- Check the 'dataFiles' array for an object where 'type' is 'XML'\n",
    "- If found, extract the URL from the 'documentUrl' field within that object\n",
    "- If no XML data is found, discard the filing\n",
    "\n",
    "\n",
    "b. If \"formType\" is one of ['8-K', '8-K/A']:\n",
    "\n",
    "- Check the 'dataFiles' array for an object where 'type' is 'XML'\n",
    "- If found, extract the URL from the 'documentUrl' field within that object\n",
    "- If not found, get the URL from the 'linkToTxt' field\n",
    "\n",
    "\n",
    "3. Process the 'documentFormatFiles' array for each filing:\n",
    "\n",
    "- Iterate through the 'documentFormatFiles' array\n",
    "- For each object in the array, check if the 'type' field starts with 'EX-10.' or 'EX-99.'\n",
    "- If the 'type' field matches 'EX-10.' or 'EX-99.', extract the URL from the 'documentUrl' field within that object\n",
    "- Discard all other objects in the 'documentFormatFiles' array where the 'type' field does not start with 'EX-10.' or 'EX-99.'\n",
    "\n",
    "\n",
    "4. Output a single line for each filing that includes:\n",
    "\n",
    "- Base fields (e.g., \"id\", \"companyName\", \"formType\", \"filingDate\", etc.)\n",
    "- Entity fields (e.g., \"entityId\", \"entityName\", etc.)\n",
    "- A dictionary containing the extracted 'EX-10.x' and 'EX-99.x' exhibits along with their associated URLs\n",
    "\n",
    "\n",
    "The goal is to have each row of the output contain all the relevant metadata for a single filing, including the primary form URL (based on the \"formType\" rules) and the associated 'EX-10.x' and 'EX-99.x' exhibit URLs (if any)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    RULE: Discard any filing where \"formType\" != ['8-K', '10-K', '10-Q', '8-K/A', '10-K/A', '10-Q/A']\n",
    "\n",
    "    \n",
    "    * Note ouput for each filing below will have a single line ouput with **all meta details for that filing**. Meaning each row will include base_fields, entity fields as well as a dictionary containing any 'EX-10.x' or 'EX-99.x' and their associated url (based on rules below)\n",
    "\n",
    "\n",
    "    RULE IF \"formType\" == ['10-K', '10-Q', '10-K/A', '10-Q/A'], Keep following data:\n",
    "        1. In 'dataFiles' > 'type' == 'XML', get url from 'documentUrl' (in 'dataFiles')\n",
    "        2. Discard if no XML data is found\n",
    "\n",
    "    RULE IF \"formType\" == ['8-K', '8-K/A'], Keep following data:\n",
    "        1. If 'dataFiles' > 'type' == 'XML', get url from 'documentUrl' (in 'dataFiles') else get url from 'linkToTxt'\n",
    "\n",
    "    RULE for finding EX-10.x and EX-99.x for each \"formType\" above:\n",
    "        1. In 'documentFormatFiles' > 'type' == 'EX-10.x' or 'EX-99.x', get value from 'documentUrl' (in documentFormatFiles)\n",
    "        2. Discard all other 'documentFormatFiles' > 'type' and in the same line store 'EX-10.x' or 'EX-99.x' along with their associated url ('documentUrl')\n",
    "\n",
    "Overall idea is that each single line of output will contain primary forms such as ['8-K', '10-K', '10-Q', '8-K/A', '10-K/A', '10-Q/A'] along with their associated EX-10.x and EX-99.x exhibits urls.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.sec.gov/Archives/edgar/data/937098/000093709825000014/0000937098-25-000014.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For storing the data in a Json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "from eventtrader.keys import SEC_API_KEY\n",
    "\n",
    "\n",
    "SERVER_URL = \"wss://stream.sec-api.io\"\n",
    "WS_ENDPOINT = SERVER_URL + \"?apiKey=\" + SEC_API_KEY\n",
    "OUTPUT_FILE = \"sec_filings.json\"  # File to save valid JSON data\n",
    "\n",
    "async def websocket_client():\n",
    "    try:\n",
    "        async with websockets.connect(WS_ENDPOINT) as websocket:\n",
    "            print(\"✅ Connected to:\", SERVER_URL)\n",
    "            filings_list = []\n",
    "\n",
    "            while True:\n",
    "                message = await websocket.recv()\n",
    "                filings = json.loads(message)\n",
    "\n",
    "                for f in filings:\n",
    "                    filings_list.append(f)  # Append each valid JSON object\n",
    "\n",
    "                # Save data every 10 filings\n",
    "                if len(filings_list) % 1 == 0:\n",
    "                    save_data(filings_list)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ An unexpected error occurred: {e}\")\n",
    "\n",
    "# Save the JSON data correctly\n",
    "def save_data(filings_list):\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(filings_list, f, indent=4)  # Ensure proper formatting\n",
    "    print(f\"✅ Data saved to {OUTPUT_FILE}\")\n",
    "\n",
    "# Run WebSocket client\n",
    "await websocket_client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load saved JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON file\n",
    "file_path = \"sec_filings.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    filings_data = json.load(file)\n",
    "\n",
    "# Flatten function to extract nested fields\n",
    "def flatten_filing(filing):\n",
    "    base_fields = {\n",
    "        \"id\": filing.get(\"id\"),\n",
    "        \"accessionNo\": filing.get(\"accessionNo\"),\n",
    "        \"cik\": filing.get(\"cik\"),\n",
    "        \"ticker\": filing.get(\"ticker\"),\n",
    "        \"companyName\": filing.get(\"companyName\"),\n",
    "        \"companyNameLong\": filing.get(\"companyNameLong\"),\n",
    "        \"formType\": filing.get(\"formType\"),\n",
    "        \"description\": filing.get(\"description\"),\n",
    "        \"filedAt\": filing.get(\"filedAt\"),\n",
    "        \"linkToTxt\": filing.get(\"linkToTxt\"),\n",
    "        \"linkToHtml\": filing.get(\"linkToHtml\"),\n",
    "        \"linkToXbrl\": filing.get(\"linkToXbrl\"),\n",
    "        \"linkToFilingDetails\": filing.get(\"linkToFilingDetails\"),\n",
    "        \"periodOfReport\": filing.get(\"periodOfReport\"),\n",
    "        \"effectivenessDate\": filing.get(\"effectivenessDate\"),\n",
    "    }\n",
    "\n",
    "    # Extract Entities\n",
    "    entities = filing.get(\"entities\", [])\n",
    "    entity_rows = []\n",
    "    for entity in entities:\n",
    "        entity_row = base_fields.copy()\n",
    "        entity_row.update({\n",
    "            \"entity_companyName\": entity.get(\"companyName\"),\n",
    "            \"entity_cik\": entity.get(\"cik\"),\n",
    "            \"entity_irsNo\": entity.get(\"irsNo\"),\n",
    "            \"entity_stateOfIncorporation\": entity.get(\"stateOfIncorporation\"),\n",
    "            \"entity_fiscalYearEnd\": entity.get(\"fiscalYearEnd\"),\n",
    "            \"entity_type\": entity.get(\"type\"),\n",
    "            \"entity_act\": entity.get(\"act\"),\n",
    "            \"entity_fileNo\": entity.get(\"fileNo\"),\n",
    "            \"entity_filmNo\": entity.get(\"filmNo\"),\n",
    "            \"entity_sic\": entity.get(\"sic\"),\n",
    "        })\n",
    "        entity_rows.append(entity_row)\n",
    "\n",
    "    # Extract Documents\n",
    "    documents = filing.get(\"documentFormatFiles\", [])\n",
    "    doc_rows = []\n",
    "    for doc in documents:\n",
    "        doc_row = base_fields.copy()\n",
    "        doc_row.update({\n",
    "            \"doc_sequence\": doc.get(\"sequence\"),\n",
    "            \"doc_description\": doc.get(\"description\"),\n",
    "            \"doc_documentUrl\": doc.get(\"documentUrl\"),\n",
    "            \"doc_type\": doc.get(\"type\"),\n",
    "            \"doc_size\": doc.get(\"size\"),\n",
    "        })\n",
    "        doc_rows.append(doc_row)\n",
    "\n",
    "    # Extract Data Files\n",
    "    data_files = filing.get(\"dataFiles\", [])\n",
    "    data_rows = []\n",
    "    for data in data_files:\n",
    "        data_row = base_fields.copy()\n",
    "        data_row.update({\n",
    "            \"data_sequence\": data.get(\"sequence\"),\n",
    "            \"data_description\": data.get(\"description\"),\n",
    "            \"data_documentUrl\": data.get(\"documentUrl\"),\n",
    "            \"data_type\": data.get(\"type\"),\n",
    "            \"data_size\": data.get(\"size\"),\n",
    "        })\n",
    "        data_rows.append(data_row)\n",
    "\n",
    "    # Extract Series and Classes Contracts Information\n",
    "    series_classes = filing.get(\"seriesAndClassesContractsInformation\", [])\n",
    "    series_rows = []\n",
    "    for series in series_classes:\n",
    "        series_row = base_fields.copy()\n",
    "        series_row.update({\n",
    "            \"series_id\": series.get(\"series\"),\n",
    "            \"series_name\": series.get(\"name\"),\n",
    "        })\n",
    "        for contract in series.get(\"classesContracts\", []):\n",
    "            contract_row = series_row.copy()\n",
    "            contract_row.update({\n",
    "                \"classContract\": contract.get(\"classContract\"),\n",
    "                \"classContract_name\": contract.get(\"name\"),\n",
    "                \"classContract_ticker\": contract.get(\"ticker\"),\n",
    "            })\n",
    "            series_rows.append(contract_row)\n",
    "\n",
    "    return entity_rows + doc_rows + data_rows + series_rows\n",
    "\n",
    "# Process all filings\n",
    "all_filing_rows = []\n",
    "for filing in filings_data:\n",
    "    all_filing_rows.extend(flatten_filing(filing))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_filing_rows)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"sec_filings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Get unique data types and their counts using Counter\n",
    "data_type_counts = Counter(df.data_type.dropna())\n",
    "data_type_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.data_type == \"XML\"]['data_documentUrl'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df[df.data_type == \"XML\"]['formType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df.formType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.id.nunique(), df.accessionNo.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.data_type == \"XML\"].id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df[(df.data_type == \"XML\") & (df.formType.isin(['8-K','10-K','10-Q']))].formType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_result = df[(df.data_type == \"XML\") & (df.formType.isin(['8-K', '10-K', '10-Q']))].formType.value_counts()\n",
    "counter_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Filter for only these 3 report types - '8-K','10-K','10-Q' or for amendments: '8-K/A', '10-K/A', '10-Q/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_types = ['8-K', '10-K', '10-Q']\n",
    "reports_to_keep = form_types + [str(r)+'/A' for r in form_types]\n",
    "\n",
    "# Since they are always in XML \n",
    "# mask1 = [df.formType.isin(reports_to_keep) & (df.data_type == \"XML\")]\n",
    "\n",
    "reports_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of df before:{len(df)}\")\n",
    "# df = df[df.formType.isin(reports_to_keep) & (df.data_type == \"XML\")]\n",
    "print(f\"Length of df after:{len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplimentary documents to store (ALWAYS filed as part of a primary filing -  (10-K, 10-Q, or 8-K).)\n",
    "    All EX-10.x (Material contracts)\n",
    "    All EX-99.x (Miscellaneous exhibits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.formType.isin(['8-K', '10-K', '10-Q'])].doc_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for EX-10.x and EX-99.x\n",
    "mask = df['doc_type'].str.startswith('EX-10.') | df['doc_type'].str.startswith('EX-99.')\n",
    "# df[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def filter_sec_filings(df):\n",
    "    \"\"\"\n",
    "    Filter SEC filings:\n",
    "    1. Keep 10-K/10-Q that have XBRL (checking all XBRL-related data_types)\n",
    "    2. Keep all 8-K\n",
    "    3. Keep their EX-10.x and EX-99.x exhibits\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define XBRL-related patterns\n",
    "    xbrl_pattern = r'XML|EX-101\\.'\n",
    "    \n",
    "    # Get accession numbers of filings with XBRL data\n",
    "    xbrl_accessions = df[\n",
    "        df['data_type'].str.contains(xbrl_pattern, na=False)\n",
    "    ]['accessionNo'].unique()\n",
    "    \n",
    "    # Print XBRL validation info\n",
    "    print(\"\\nXBRL Validation Summary:\")\n",
    "    ten_k_q = df[df['formType'].isin(['10-K', '10-Q'])]\n",
    "    total_acc = ten_k_q['accessionNo'].unique()\n",
    "    print(f\"Total 10-K/10-Q accession numbers: {len(total_acc)}\")\n",
    "    print(f\"With XBRL: {len(set(total_acc) & set(xbrl_accessions))}\")\n",
    "    print(f\"Without XBRL: {len(set(total_acc) - set(xbrl_accessions))}\")\n",
    "    \n",
    "    # Filter main documents\n",
    "    main_forms = ['8-K', '10-K', '10-Q']\n",
    "    form_pattern = '|'.join(f\"^{form}(/A)?$\" for form in main_forms)\n",
    "    \n",
    "    # For 10-K and 10-Q, must have XBRL\n",
    "    main_docs = df[\n",
    "        (df['formType'].str.match(form_pattern, na=False)) &\n",
    "        (\n",
    "            (df['formType'].str.startswith('8-K')) |  # Keep all 8-Ks\n",
    "            (df['accessionNo'].isin(xbrl_accessions))  # Only 10-K/Q with XBRL\n",
    "        )\n",
    "    ].copy()\n",
    "    \n",
    "    # Get valid accession numbers\n",
    "    valid_accessions = main_docs['accessionNo'].unique()\n",
    "    \n",
    "    # Get exhibits for valid accessions\n",
    "    exhibit_pattern = r'^EX-(?:10\\.|99\\.)'\n",
    "    exhibits = df[\n",
    "        (df['accessionNo'].isin(valid_accessions)) &\n",
    "        (df['doc_type'].str.match(exhibit_pattern, na=False))\n",
    "    ].copy()\n",
    "    \n",
    "    # Combine and categorize\n",
    "    filtered_df = pd.concat([main_docs, exhibits])\n",
    "    \n",
    "    # Add category\n",
    "    def get_category(row):\n",
    "        if pd.isna(row['doc_type']):\n",
    "            return 'MAIN'\n",
    "        elif row['doc_type'].startswith('EX-10.'):\n",
    "            return 'MATERIAL_CONTRACT'\n",
    "        elif row['doc_type'].startswith('EX-99.'):\n",
    "            return 'MISC_EXHIBIT'\n",
    "        return 'MAIN'  # Default to MAIN for non-exhibit docs\n",
    "    \n",
    "    filtered_df['document_category'] = filtered_df.apply(get_category, axis=1)\n",
    "    \n",
    "    # Additional validation info\n",
    "    print(\"\\nXBRL Data Types found:\")\n",
    "    print(df[df['data_type'].str.contains(xbrl_pattern, na=False)]['data_type'].value_counts())\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read CSV\n",
    "    df = pd.read_csv('sec_filings.csv')\n",
    "    \n",
    "    # Apply filter\n",
    "    filtered_df = filter_sec_filings(df)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nDocument Categories Summary:\")\n",
    "    print(filtered_df['document_category'].value_counts())\n",
    "    \n",
    "    print(\"\\nForm Types Summary:\")\n",
    "    print(filtered_df[filtered_df['document_category'] == 'MAIN']['formType'].value_counts())\n",
    "    \n",
    "    print(\"\\nExhibit Types Summary:\")\n",
    "    exhibits = filtered_df[filtered_df['document_category'].isin(['MATERIAL_CONTRACT', 'MISC_EXHIBIT'])]\n",
    "    print(exhibits['doc_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('your_sec_filings.csv')\n",
    "filtered_df = filter_sec_filings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.sec.gov/Archives/edgar/data/937098/000093709825000016/tnet-123124ex1028warren.htm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EventTrader Environment",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
