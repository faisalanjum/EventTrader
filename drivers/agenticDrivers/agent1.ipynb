{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd4fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you started Jupyter from the EventMarketDB directory with .env loaded\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment\")\n",
    "\n",
    "# Initialize the client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f458d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERPLEXITY_API_KEY = os.getenv('PERPLEXITY_API_KEY')\n",
    "PERPLEXITY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26456da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In its latest 10-Q for fiscal Q2 2025, Nvidia’s **Management’s Discussion and Analysis** (MD&A) highlighted record-high revenues and profit, with exceptional performance in the Data Center segment. The growth was primarily driven by surging demand for the Hopper GPU platform, improving supply and availability, and strong AI infrastructure investments by cloud service providers and enterprise customers[1][3]. \n",
      "\n",
      "Key points included:\n",
      "- **Total revenue for Q2 2025** was $30.0 billion, surpassing consensus estimates due to the Data Center segment's revenue of $26.3 billion, up sharply year-over-year and quarter-over-quarter[1][3].\n",
      "- The **Data Center segment** continues to be the dominant driver, reflecting rapid enterprise and internet-sector adoption, especially for AI workloads[1][3].\n",
      "- Management noted a **deceleration in sequential growth** in the Data Center segment compared to prior quarters, signaling a potential moderation of the hypergrowth phase[3].\n",
      "- Despite strong topline growth, Nvidia reported a **modest dip in gross margin** for Q2: the Data Center non-GAAP gross margin dropped to 78%, with total company gross margin around 75%, attributed to a shift in product mix within the Data Center business[1].\n",
      "- Nvidia raised its guidance for the following quarter, expecting $33.1 billion in revenue (again about $1 billion above street consensus), largely fueled by anticipated continued Data Center strength and the impending ramp-up of the next-generation Blackwell chips[1].\n",
      "- Management also highlighted a **$50 billion share repurchase authorization**, suggesting both confidence in long-term prospects and some concern about fewer near-term opportunities for major capital deployment[1].\n",
      "- Risks discussed included **supply constraints** for advanced GPUs (notably Blackwell and H200), intensifying competition, and geopolitical headwinds, especially relating to export controls in China[2].\n",
      "- Looking ahead, analysts and management foresee sustained growth, particularly from the launch and ramp of Blackwell architecture, with multi-year tailwinds in AI and cloud infrastructure demand[1][2].\n",
      "\n",
      "While Nvidia does not provide the full text of its MD&A in press releases or summaries, these updates echo the core disclosures found in that section: explanations of revenue and margin performance, growth drivers, supply chain dynamics, risks, and forward-looking statements tied to product cycles and market opportunities[1][2][3].\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def perplexity_sec_search(query: str) -> str:\n",
    "    \"\"\"Uses Perplexity SEC mode to answer finance questions from filings.\"\"\"\n",
    "    api_key = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"sonar-pro\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}],\n",
    "        \"search_mode\": \"sec\",\n",
    "        \"web_search_options\": {\"search_context_size\": \"medium\"},\n",
    "    }\n",
    "    resp = requests.post(\"https://api.perplexity.ai/chat/completions\", headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "res = perplexity_sec_search.invoke(\"What did Nvidia report in 'Management’s Discussion and Analysis' in its latest 10-Q?\")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699e8726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')\n",
    "TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc507b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2051585/3227139208.py:2: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(max_results=3)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25daf4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is LangGraph? - IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/langgraph',\n",
       "  'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\nLLM applications: By using LangGraph’s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.',\n",
       "  'score': 0.94608605},\n",
       " {'title': \"Introduction to LangGraph: A Beginner's Guide - Medium\",\n",
       "  'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "  'content': 'What is LangGraph?\\n==================\\n\\nLangGraph is a library built on top of LangChain, designed to add cyclic computational capabilities to your LLM applications. While LangChain allows you to define chains of computation (Directed Acyclic Graphs or DAGs), LangGraph introduces the ability to add cycles, enabling more complex, agent-like behaviors where you can call an LLM in a loop, asking it what action to take next.\\n\\nKey Concepts\\n============ [...] Conclusion\\n==========\\n\\nLangGraph is a versatile tool for building complex, stateful applications with LLMs. By understanding its core concepts and working through simple examples, beginners can start to leverage its power for their projects. Remember to pay attention to state management, conditional edges, and ensuring there are no dead-end nodes in your graph. Happy coding!\\n\\nLangchain\\n\\nLlm\\n\\nAI\\n\\nChatbots\\n\\nPython\\n\\n\\n--------------\\n\\n\\n\\nKiss Tibor (Cloud Mentor) he/him\\n\\nSep 20, 2024',\n",
       "  'score': 0.94174546},\n",
       " {'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "  'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': \"Imagine you're building a complex, multi-agent large language model (LLM) application. It's exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\\n\\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. [...] LangGraph can be used to build a wide range of applications.\\n\\n### Chatbots\\n\\nLangGraph is ideal for developing sophisticated chatbots that can handle a wide array of user requests. By leveraging multiple LLM agents, these chatbots can process natural language queries, provide accurate responses, and seamlessly switch between different conversation topics. The ability to manage state and coordinate interactions ensures that the chatbot maintains context and delivers a coherent user experience. [...] LangGraph enables us to create stateful, multi-actor applications utilizing LLMs as easily as possible. It extends the capabilities of LangChain, introducing the ability to create and manage cyclical graphs, which are pivotal for developing sophisticated agent runtimes. The core concepts of LangGraph include: graph structure, state management, and coordination.\\n\\n### Graph structure\",\n",
       "  'score': 0.92715925}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e31cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78d80d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bx99K3sGR6fggmJapDMxFZbfSHy0R', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--81095e28-d365-41fa-94e2-2df71e00efe5-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages          \n",
    "gpt4o_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a18532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
